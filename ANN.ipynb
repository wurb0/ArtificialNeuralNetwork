{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "53739f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data objects\n",
    "#training loop\n",
    "#eval \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a225a863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Apple GPU\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # NVIDIA GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # fallback\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7e95c990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>205</td>\n",
       "      <td>196</td>\n",
       "      <td>213</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>203</td>\n",
       "      <td>174</td>\n",
       "      <td>151</td>\n",
       "      <td>188</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      9       0       0       0       0       0       0       0       0   \n",
       "1      7       0       0       0       0       0       0       0       0   \n",
       "2      0       0       0       0       0       0       1       0       0   \n",
       "3      8       0       0       0       0       0       0       0       0   \n",
       "4      8       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         7         0        50       205       196   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...       142       142       142        21         0         3   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...       213       203       174       151       188        10   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       213       165         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fmnist_small.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a444471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split data\n",
    "x = df.iloc[:,1:].values #pixel values starting from col 1\n",
    "y = df.iloc[:,0].values # y is the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1be27720",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "da320f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the features ; vals 0 to 1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f16c5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create customdataset class\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        #convert to pytroch tensors\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "01a99d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataset object\n",
    "train_dataset = CustomDataset(x_train,y_train)\n",
    "#create test dataset object\n",
    "test_dataset = CustomDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "86831c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define NN class\n",
    "\n",
    "class myNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_hidden_layers, neurons_per_layer,dropout_rate):\n",
    "        super().__init__()\n",
    "\n",
    "        layers=[]\n",
    "\n",
    "        for i in range(num_hidden_layers):\n",
    "            layers.append(nn.Linear(input_dim,neurons_per_layer))\n",
    "            layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = neurons_per_layer\n",
    "        \n",
    "        layers.append(nn.Linear(neurons_per_layer,output_dim)) #this is the output layer\n",
    "\n",
    "        self.model = nn.Sequential(*layers) #* unwraps the layers list\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2ead84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #set learning rate & epochs\n",
    "# epochs = 100\n",
    "# learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fb8ff96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Objective function: USING OP\n",
    "\n",
    "def objective(trial):\n",
    "    #next hyperparamter values from the search space using optima\n",
    "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1,5)\n",
    "    neurons_per_layer = trial.suggest_int('neurons_per_layer',8,128, step=8)\n",
    "    epochs = trial.suggest_int('epochs', 10,50,step=10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5,1e-1,log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
    "    batch_size = trial.suggest_categorical('batch_size',[16,32,64,128])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop'])\n",
    "    weight_decay = trial.suggest_float('weight_decay',1e-5,1e-3,log=True)\n",
    "\n",
    "\n",
    "\n",
    "# {'num_hidden_layers': 2,\n",
    "#  'neurons_per_layer': 112,\n",
    "#  'epochs': 30,\n",
    "#  'learning_rate': 0.0010005061612763301,\n",
    "#  'dropout_rate': 0.4,\n",
    "#  'batch_size': 32,\n",
    "#  'optimizer': 'Adam',\n",
    "#  'weight_decay': 0.00019590116325074537}\n",
    "\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size , shuffle=True, pin_memory=True) #pin memory batches memory together and makes it run faster?\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    #model init\n",
    "    input_dim = 784 # 28x28 pic flattenned\n",
    "    output_dim = 10 #10 classes\n",
    "\n",
    "    model = myNN(input_dim, output_dim , num_hidden_layers, neurons_per_layer, dropout_rate)\n",
    "    model.to(device)\n",
    "\n",
    "    #optimizer selection\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.1 , weight_decay=1e-4)\n",
    "\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "       optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer =optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    #training loop\n",
    "    for epoch in range(epochs):\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            #move data to gpu\n",
    "            batch_features, batch_labels = batch_features.to(device) , batch_labels.to(device)\n",
    "\n",
    "            #forward pass\n",
    "            outputs = model(batch_features)\n",
    " \n",
    "            # calculate loss\n",
    "            loss = criterion(outputs , batch_labels)\n",
    "\n",
    "            #back pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            #update grads\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    #eval mode\n",
    "    # model.eval() \n",
    "    # total = 0\n",
    "    # correct = 0\n",
    "\n",
    "    # with torch.no_grad():\n",
    "\n",
    "    #     for batch_features, batch_labels in test_loader:\n",
    "    #   # move data to gpu\n",
    "    #         batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "    #         outputs = model(batch_features)\n",
    "\n",
    "    #         _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    #         total = total + batch_labels.shape[0]\n",
    "\n",
    "    #         correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "    #     accuracy = correct/total\n",
    "\n",
    "    # print(accuracy)\n",
    "\n",
    "    # #return accuracy\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     for batch_features, batch_labels in train_loader:\n",
    "    #         batch_features, batch_labels = batch_features.to(device) , batch_labels.to(device)\n",
    "\n",
    "    #         outputs = model(batch_features)\n",
    "    #         _, predicted= torch.max(outputs,1)\n",
    "    #         total = total + batch_labels.shape[0]\n",
    "    #         correct = correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "    # print(correct/total)\n",
    "\n",
    "    # return accuracy\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    #TEST ACCURACY \n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in test_loader:\n",
    "            #move data to gpu\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "            _ , predicted = torch.max(outputs, 1)\n",
    "\n",
    "            test_total = test_total + batch_labels.shape[0]\n",
    "            test_correct = test_correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # TRAIN ACCURACY to see if it overfits\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "            outputs = model(batch_features)\n",
    "            _ , predicted = torch.max(outputs, 1)\n",
    "\n",
    "            train_total = train_total + batch_labels.shape[0]\n",
    "            train_correct = train_correct + (predicted == batch_labels).sum().item()\n",
    "\n",
    "    train_acc = train_correct / train_total\n",
    "    print(f\"train accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9504a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:13:13,037] A new study created in memory with name: no-name-d523864f-7af9-40d2-8f51-0f8512983b8d\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='maximize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2071a202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:22:01,705] Trial 4 finished with value: 0.43333333333333335 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 56, 'epochs': 30, 'learning_rate': 1.6287448407982486e-05, 'dropout_rate': 0.1, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 6.342657815408323e-05}. Best is trial 4 with value: 0.43333333333333335.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.4358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:22:02,930] Trial 5 finished with value: 0.19583333333333333 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 112, 'epochs': 10, 'learning_rate': 9.55130036090169e-05, 'dropout_rate': 0.4, 'batch_size': 128, 'optimizer': 'SGD', 'weight_decay': 9.830040622224442e-05}. Best is trial 4 with value: 0.43333333333333335.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.1958\n",
      "train accuracy: 0.2046\n",
      "Test Accuracy: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:22:25,366] Trial 6 finished with value: 0.8208333333333333 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 56, 'epochs': 30, 'learning_rate': 0.0017433009083455172, 'dropout_rate': 0.2, 'batch_size': 16, 'optimizer': 'SGD', 'weight_decay': 3.786037165493035e-05}. Best is trial 6 with value: 0.8208333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:22:38,438] Trial 7 finished with value: 0.6108333333333333 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 24, 'epochs': 40, 'learning_rate': 0.0007831608343386735, 'dropout_rate': 0.30000000000000004, 'batch_size': 64, 'optimizer': 'SGD', 'weight_decay': 0.0004038543748289501}. Best is trial 6 with value: 0.8208333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6108\n",
      "train accuracy: 0.6506\n",
      "Test Accuracy: 0.7875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:23:28,979] Trial 8 finished with value: 0.7875 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 40, 'epochs': 50, 'learning_rate': 0.0065266026854516185, 'dropout_rate': 0.5, 'batch_size': 16, 'optimizer': 'SGD', 'weight_decay': 4.064651477973213e-05}. Best is trial 6 with value: 0.8208333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8071\n",
      "Test Accuracy: 0.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:23:38,247] Trial 9 finished with value: 0.6675 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 120, 'epochs': 10, 'learning_rate': 0.07292469605213642, 'dropout_rate': 0.5, 'batch_size': 16, 'optimizer': 'Adam', 'weight_decay': 4.3926634148893444e-05}. Best is trial 6 with value: 0.8208333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.6744\n",
      "Test Accuracy: 0.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:24:06,478] Trial 10 finished with value: 0.6691666666666667 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 24, 'epochs': 50, 'learning_rate': 0.0014115702172650697, 'dropout_rate': 0.5, 'batch_size': 32, 'optimizer': 'SGD', 'weight_decay': 1.3647737406630543e-05}. Best is trial 6 with value: 0.8208333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.7004\n",
      "Test Accuracy: 0.7833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:24:40,856] Trial 11 finished with value: 0.7833333333333333 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 80, 'epochs': 40, 'learning_rate': 0.016694309114653434, 'dropout_rate': 0.1, 'batch_size': 32, 'optimizer': 'RMSprop', 'weight_decay': 0.0001786024273150858}. Best is trial 6 with value: 0.8208333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:24:56,941] Trial 12 finished with value: 0.6391666666666667 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 40, 'epochs': 50, 'learning_rate': 0.07462100244134426, 'dropout_rate': 0.30000000000000004, 'batch_size': 64, 'optimizer': 'Adam', 'weight_decay': 0.0007824612778337822}. Best is trial 6 with value: 0.8208333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6392\n",
      "train accuracy: 0.6677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-03 17:25:01,816] Trial 13 finished with value: 0.2941666666666667 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 72, 'epochs': 20, 'learning_rate': 5.854218073765489e-05, 'dropout_rate': 0.5, 'batch_size': 128, 'optimizer': 'Adam', 'weight_decay': 0.0006255731282252999}. Best is trial 6 with value: 0.8208333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2942\n",
      "train accuracy: 0.2921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_hidden_layers': 1,\n",
       " 'neurons_per_layer': 56,\n",
       " 'epochs': 30,\n",
       " 'learning_rate': 0.0017433009083455172,\n",
       " 'dropout_rate': 0.2,\n",
       " 'batch_size': 16,\n",
       " 'optimizer': 'SGD',\n",
       " 'weight_decay': 3.786037165493035e-05}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.optimize(objective,n_trials=10)\n",
    "study.best_value\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2075501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1.1362\n",
      "Epoch 2/30, Loss: 0.7224\n",
      "Epoch 3/30, Loss: 0.6375\n",
      "Epoch 4/30, Loss: 0.5920\n",
      "Epoch 5/30, Loss: 0.5491\n",
      "Epoch 6/30, Loss: 0.5307\n",
      "Epoch 7/30, Loss: 0.5045\n",
      "Epoch 8/30, Loss: 0.4885\n",
      "Epoch 9/30, Loss: 0.4751\n",
      "Epoch 10/30, Loss: 0.4439\n",
      "Epoch 11/30, Loss: 0.4428\n",
      "Epoch 12/30, Loss: 0.4151\n",
      "Epoch 13/30, Loss: 0.4127\n",
      "Epoch 14/30, Loss: 0.3893\n",
      "Epoch 15/30, Loss: 0.3982\n",
      "Epoch 16/30, Loss: 0.3706\n",
      "Epoch 17/30, Loss: 0.3776\n",
      "Epoch 18/30, Loss: 0.3673\n",
      "Epoch 19/30, Loss: 0.3619\n",
      "Epoch 20/30, Loss: 0.3529\n",
      "Epoch 21/30, Loss: 0.3494\n",
      "Epoch 22/30, Loss: 0.3350\n",
      "Epoch 23/30, Loss: 0.3253\n",
      "Epoch 24/30, Loss: 0.3220\n",
      "Epoch 25/30, Loss: 0.3084\n",
      "Epoch 26/30, Loss: 0.3127\n",
      "Epoch 27/30, Loss: 0.2891\n",
      "Epoch 28/30, Loss: 0.3031\n",
      "Epoch 29/30, Loss: 0.2989\n",
      "Epoch 30/30, Loss: 0.3031\n",
      "Final Test Accuracy: 0.8525\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 2\n",
    "neurons_per_layer = 112\n",
    "epochs = 30\n",
    "learning_rate = 0.0010005061612763301\n",
    "dropout_rate = 0.4\n",
    "batch_size = 32\n",
    "optimizer_name = 'Adam' \n",
    "weight_decay = 0.00019590116325074537\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size= batch_size , shuffle= True , pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size , shuffle=False, pin_memory=True)\n",
    "\n",
    "#Model:\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "\n",
    "model = myNN(input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate).to(device)\n",
    "\n",
    "#loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if optimizer_name == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "elif optimizer_name == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "else:\n",
    "    optimizer =optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#training loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_epoch_loss = 0\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features, batch_labels = batch_features.to(device) , batch_labels.to(device)\n",
    "\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animal-classifier-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
